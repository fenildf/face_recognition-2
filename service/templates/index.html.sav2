<!DOCTYPE html>
<html xmlns:th="http://www.thymeleaf.org" xmlns:layout="http://www.ultraq.net.nz/web/thymeleaf/layout" layout:decorate="layout">

<head>
    <script async type="text/javascript" th:src="@{/opencv/opencv.js}"></script>
    <title>Self-Service Portal</title>
</head>

<body>
<h2>Trying OpenCV Javascript Computer Vision</h2>
<p id="status">Loading with OpenCV.js...</p>

<video id="video" autoplay="true" play width="300" height="225"></video> <br/>
<canvas id="canvasOutput" autoplay="true" width="300" height="225"></canvas>

<!--div>
<div class="inputoutput">
<img id="imageSrc" alt="No Image" />
<div class="caption">ImageScr<input type="file" id="fileInput" name="file" /></div>
</div>
<div class="inputoutput">
<canvas id="canvasOutput" ></canvas>
<div class="caption">canvasOutput</div>
</div>
</div-->
<script type="text/javascript">
    function onOpenCvReady() {
        alert("loaded")
        document.getElementById('status').innerHTML = 'OpenCV.js is ready.';
    }
</script>
<script src="static/js/utils.js" type="text/javascript"></script>
<script src="static/js/opencv.js" onload="onOpenCvReady;" type="text/javascript"></script>

<script type="text/javascript">
    let utils = new Utils('errorMessage');

    navigator.mediaDevices.getUserMedia({
        video: true,
        audio: false
    })
        .then(function(stream) {
            video.srcObject = stream;
            video.play();
        })
        .catch(function(err) {
            console.log("An error occured While accessing media! " + err);
        });

    let video = document.getElementById('video');
    let src = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let dst = new cv.Mat(video.height, video.width, cv.CV_8UC4);
    let gray = new cv.Mat();
    let cap = new cv.VideoCapture(video);
    let faces = new cv.RectVector();
    let classifier = new cv.CascadeClassifier();



    const FPS = 30;

    function processVideo() {
        try {
            //if (!streaming) {
            //    // clean and stop.
            //    src.delete();
            //    dst.delete();
            //    gray.delete();
            //    faces.delete();
            //    classifier.delete();
            //    return;
            //}
            let begin = Date.now();
            // start processing.
            cap.read(src);
            src.copyTo(dst);
            cv.cvtColor(dst, gray, cv.COLOR_RGBA2GRAY, 0);
            // detect faces.
            classifier.detectMultiScale(gray, faces, 1.1, 3, 0);
            // draw faces.
            for (let i = 0; i < faces.size(); ++i) {
                let face = faces.get(i);
                let point1 = new cv.Point(face.x, face.y);
                let point2 = new cv.Point(face.x + face.width, face.y + face.height);
                cv.rectangle(dst, point1, point2, [255, 0, 0, 255]);
            }
            cv.imshow('canvasOutput', dst);
            // schedule the next one.
            let delay = 1000 / FPS - (Date.now() - begin);
            setTimeout(processVideo, delay);
        }
        catch (err) {
            console.log(err);
        }
    };
    utils.loadOpenCv(() => {
        let faceCascadeFile = 'static/haarcascade_frontalface_default.xml'
        utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
            //startAndStop.removeAttribute('disabled');
        });
    });
    // load pre-trained classifiers
    classifier.load(faceCascadeFile);

//schedule the first one.
    setTimeout(processVideo, 0);


</script>

</body>

</html>